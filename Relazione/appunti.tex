\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

% Questo comando importa i miei comandi personali che semplificano due o tre cagate
\input{.Latex_stuff/commands.tex}



\sloppy
\begin{document}

\begin{titlepage}
\begin{center}
	\Large{\textbf{Documentation for Algorithms for Massive Datasets project: Turkish lira recognizer}}
\vfill
\normalsize{Caccaro Sebastiano}\\
\normalsize{Cavagnino Matteo}\\
\normalsize{A.A.2019/2020}
\end{center}
\end{titlepage}
\pagenumbering{Roman}

\vspace*{\fill}
\textit{We declare that this material, which We now submit for assessment, is entirely our own work and has not been taken from the work of others, save and to the extent that such work has been cited and acknowledged within the text of our work. We understand that plagiarism, collusion, and copying are grave and serious offences in the university and accept the penalties that would be imposed should we engage in plagiarism, collusion or copying. This assignment, or any part of it, has not been previously submitted by us or any other person for assessment on this or any other course of study.}
\vspace*{\fill}

\newpage

\tableofcontents

\clearpage
%magari c'è qualcosa di un po piu slick di una section per questo

\pagenumbering{arabic}

\newpage
\section{Introduction}
The Objective of this project is to build a Turkish Lira banknotes image recognizer through a Convolutional Neural Network.
The proposed solution, based on Tensorflow libraries, contains steps to dinamically download the dataset, preprocess the images in it and use the processed images to train a 
Convolutional Neural Network in recognizing and classifying them.
Since the given dataset contains many images and since the request is to classify some precise details of them, it's expected to achieve good results from the proposed solution and in particular
from the proposed model.

\newpage
\section{The Turkish Lira banknotes dataset}
The chosen dataset <add ref> is originally composed of 6000 images of Turkish Lira banknotes, 
organized in folders grouping banknotes by their value and already splitted in training and validation set.

\newpage
\subsection{Preprocessing techniques applied to the dataset}
To start the pre-processing phase, it's needed to scale the images to a more appropriate size to not overload the machine memory; the size scale factor used in this project is 5.
The given dataset was provided with two text files listing the images belonging to the training and to the validation datasets; using this lists, the images files have been divided in the
two respective labeled datasets. 
The training dataset has been created using a "prefetch dataset" and the validation dataset has been created using a "repeat dataset" both using also batching and caching techniques.


\newpage
\subsection{Considered algorithms and their implmentation}
?

%meglio fare una sezione a riguardo secondo me, ci mettiamo tutta la parte sul batching, memorizzazione , uso di disco e ram e scaling delle immagini  
\newpage
\section{Scalability of the proposed solution}
The Scalability of this project is granted by (batching, caching, img scaling, ? ...) 

%esporre i modelli usati e i relativi risultati in ordine temporale in modo da fornire una sequenza dei ragionamenti fatti
\newpage
\section{Experiments and results}
Different models have been tested during the developing process; in this section some of those will be shown and the relative results will be discussed.
\subsection{Model summary}
For each tested model the following data will be reported:
\begin{itemize}
\item The NN architecture
\item Hyperparameters used
\item Data on accuracy for three repeated runs
\item Graph of one of the runs
\item Comment on the architecture and results
\end{itemize}
In the layer tables the input  layer will not be reported, as it always corresponds to resized image size (\texttt{144,256,3}).\\
Also note that some abbreviations are used in the Layer Config field in order to for the table to fit:
\begin{itemize}
\item \texttt{k} stands for \texttt{kernel size}
\item \texttt{s} stands for \texttt{strides}
\item \texttt{f} stands for \texttt{filters}
\item \texttt{p} stands for \texttt{pool size}
\item \texttt{r} stands for \texttt{rate}
\end{itemize}

%Commands needed for table
\newcommand{\conv}{Convolution(\texttt{Conv2d})}
\newcommand{\convP}[3]{\texttt{k=#1, s=#2, f=#3}}
\newcommand{\convKSF}[3]{\convP{#1}{#2}{#3}}

\newcommand{\flt}{Flatten(\texttt{Flatten})}

\newcommand{\dns}{Dense(\texttt{Dense})}
\newcommand{\dnsP}[1]{\texttt{u=#1}}

\newcommand{\pool}{MaxPooling(\texttt{MaxPooling2D})}
\newcommand{\poolN}{\texttt{p=2x2}}

\newcommand{\drop}{Dropout(\texttt{Dropout})}
\newcommand{\dropR}[1]{\texttt{r=#1}}

\newcommand{\bat}{Batch Norm.(\texttt{BatchN.})}
\subsection{Models}

\subsubsection{Baseline Model}
\input{Models/baseline.tex}

\subsubsection{Convolution Model}
\input{Models/conv.tex}

\subsubsection{Convolution and Pooling Model}
\input{Models/conv_pool.tex}

\subsubsection{Convolution and Pooling Model with Dropout}
\input{Models/conv_pool_drop.tex}

\subsubsection{Batch Normalization Model}
\input{Models/bn.tex}







\newpage
\section{Conclusions}
As seen in the previous sections, after a few experiments, this project has been succesful in classifying the images of Turkish 
Lira banknotes with high accuracy and low data loss.
(altro?)




Esempio di citazione\cite{latexcompanion}

\newpage
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{9}
\bibitem{latexcompanion} 
Michel Goossens, Frank Mittelbach, and Alexander Samarin. 
\textit{The \LaTeX\ Companion}. 
Addison-Wesley, Reading, Massachusetts, 1993.

\bibitem{einstein} 
Albert Einstein. 
\textit{Zur Elektrodynamik bewegter K{\"o}rper}. (German) 
[\textit{On the electrodynamics of moving bodies}]. 
Annalen der Physik, 322(10):891–921, 1905.

\bibitem{knuthwebsite} 
Knuth: Computers and Typesetting,
\\\texttt{http://www-cs-faculty.stanford.edu/\~{}uno/abcde.html}
\end{thebibliography}


\end{document}
