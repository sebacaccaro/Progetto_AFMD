\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

% Questo comando importa i miei comandi personali che semplificano due o tre cagate
\input{.Latex_stuff/commands.tex}
%\usepackage[demo]{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\renewcommand\UrlFont{\color{blue}\rmfamily}
\usepackage{tikz}
\newcommand{\lira}{%
\begin{tikzpicture}[x=0.08em, y=0.08em, xscale=0.03, yscale=-0.03, inner sep=0pt, outer sep=0pt]
\fill (54.3355,9.3092) .. controls (70.3869,9.3092) and (79.7110,9.3092) ..
  (82.3075,9.3092) .. controls (82.3075,12.1418) and (82.3075,24.2985) ..
  (82.3075,45.7791) .. controls (82.3075,67.2598) and (82.3075,79.2984) ..
  (82.3075,81.8950) -- (167.2860,51.0903) .. controls (167.2860,59.3521) and
  (167.2860,66.7877) .. (167.2860,73.3971) -- (82.3075,104.2018) .. controls
  (82.3075,105.1460) and (82.3075,107.1525) .. (82.3075,110.2211) .. controls
  (82.3075,113.2898) and (82.3075,115.2962) .. (82.3075,116.2404) --
  (128.3375,99.9529) -- (167.2860,85.4358) .. controls (167.2860,86.8521) and
  (167.2860,90.4518) .. (167.2860,96.2351) .. controls (167.2860,102.0184) and
  (167.2860,105.5001) .. (167.2860,106.6804) .. controls (167.2860,107.6246) and
  (167.0499,108.0967) .. (166.5778,108.0967) -- (84.7861,137.4851) .. controls
  (83.8419,137.9572) and (83.0157,138.4293) .. (82.3075,138.9014) .. controls
  (82.3075,153.3005) and (82.3075,173.1878) .. (82.3075,198.5633) .. controls
  (82.3075,223.9388) and (82.3075,243.8262) .. (82.3075,258.2253) .. controls
  (82.3075,258.2253) and (82.3075,258.3433) .. (82.3075,258.5794) .. controls
  (82.3075,258.8154) and (82.3075,258.9334) .. (82.3075,258.9334) .. controls
  (103.7882,256.3369) and (122.7903,248.1931) .. (139.3139,234.5021) .. controls
  (157.4899,219.6309) and (169.6465,201.1009) .. (175.7838,178.9121) .. controls
  (178.3804,168.7619) and (179.6787,158.6117) .. (179.6787,148.4614) .. controls
  (179.6787,148.4614) and (189.1207,148.4614) .. (208.0048,148.4614) .. controls
  (208.0048,171.3584) and (202.4576,192.9571) .. (191.3632,213.2575) .. controls
  (183.5735,228.8369) and (172.9512,242.2918) .. (159.4963,253.6223) .. controls
  (146.9856,264.7167) and (132.9405,273.2145) .. (117.3611,279.1158) .. controls
  (97.0607,286.9055) and (76.0522,289.6201) .. (54.3355,287.2596) .. controls
  (54.3355,271.9163) and (54.3355,248.9013) .. (54.3355,218.2146) .. controls
  (54.3355,187.5279) and (54.3355,164.3949) .. (54.3355,148.8155) .. controls
  (54.3355,148.8155) and (52.8011,149.4057) .. (49.7325,150.5859) --
  (1.2239,167.9357) .. controls (1.2239,160.8541) and (1.2239,153.4185) ..
  (1.2239,145.6288) -- (54.3355,126.5087) .. controls (54.3355,125.0924) and
  (54.3355,120.9615) .. (54.3355,114.1160) .. controls (51.7389,115.2962) and
  (48.2571,116.7126) .. (43.8902,118.3649) .. controls (39.5232,120.0173) and
  (36.7496,120.9615) .. (35.5694,121.1975) -- (7.5973,131.4658) .. controls
  (7.5973,131.4658) and (6.8301,131.7018) .. (5.2958,132.1739) .. controls
  (3.7615,132.6460) and (2.4042,133.0001) .. (1.2239,133.2361) .. controls
  (1.2239,121.9057) and (1.2239,114.4701) .. (1.2239,110.9293) --
  (54.3355,92.1632) .. controls (54.3355,81.7770) and (54.3355,67.9680) ..
  (54.3355,50.7362) .. controls (54.3355,33.5045) and (54.3355,19.6955) ..
  (54.3355,9.3092) -- cycle;

\end{tikzpicture}}


\sloppy
\begin{document}

\begin{titlepage}
\begin{center}
	\Large{\textbf{Documentation for Algorithms for Massive Datasets project: Turkish lira recognizer}}
\vfill
\normalsize{Caccaro Sebastiano}\\
\normalsize{Cavagnino Matteo}\\
\normalsize{A.A.2019/2020}
\end{center}
\end{titlepage}
\pagenumbering{Roman}

\vspace*{\fill}
\textit{We declare that this material, which We now submit for assessment, is entirely our own work and has not been taken from the work of others, save and to the extent that such work has been cited and acknowledged within the text of our work. We understand that plagiarism, collusion, and copying are grave and serious offences in the university and accept the penalties that would be imposed should we engage in plagiarism, collusion or copying. This assignment, or any part of it, has not been previously submitted by us or any other person for assessment on this or any other course of study.}
\vspace*{\fill}

\newpage

\tableofcontents

\clearpage
%magari c'Ã¨ qualcosa di un po piu slick di una section per questo

\pagenumbering{arabic}

\newpage
\section{Introduction}

The goal of this project is to build and train a classifier for Turkish Liras based on the \textit{Turkish Lira Banknote Dataset} (\autoref{sec:dataset}).\\
The classifier is developed using Convolutional Neural Networks (from now on CNN). The CNN is coded using python3 and using the Tensorflow and Keras libraries.

\subsection{References and sources}
In order to develop the project some other sources other than the ones given during the course were consulted: all the links are cited in the \textit{Reference} section of this document.\\
The sources include also some links from the \textit{Tensorflow official documentation} from which most of the code in the project has been adapted.

\subsection{Links}
All of the code from the project is available at the following link:
\begin{center}
\url{https://github.com/sebacaccaro/Progetto_AFMD}
\end{center}
The code is available both in a python file and in a notebook which is meant to be run on Google Colab. \\
Note that in both cases a Kaggle API key is needed in order download the dataset and run the code.






\newpage
\section{Dataset}
\label{sec:dataset}
The dataset used for the project is the \textit{Turkish Lira Banknote Dataset}, available at the following link:
\begin{center}
\url{https://www.kaggle.com/baltacifatih/turkish-lira-banknote-dataset}
\end{center}

The dataset is composed by 6000 images of Turkish Lira Banknotes, organized as follows:
\begin{itemize}
\item 1000 pictures of 5\lira\ banknotes
\item 1000 pictures of 10\lira\ banknotes
\item 1000 pictures of 20\lira\ banknotes
\item 1000 pictures of 50\lira\ banknotes
\item 1000 pictures of 100\lira\ banknotes
\item 1000 pictures of 200\lira\ banknotes
\end{itemize}

Images are already splitted in \textit{train} and \textit{validation}. The training set contains 925 images for each banknote, leading to 92.5\% of the images (5550) begin used for training and the remaining 7.5\% (450) being used for validation.

\subsection{Images}
All the pictures in the dataset consist of picture of banknotes taken with different perspectives and conditions: some are just laying on different surfaces, some are held in hand, blurred, folded or partially out of frame, ecc.

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{Immagini/folded}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\textwidth]{Immagini/plain}
  \label{fig:sub2}
\end{subfigure}
\caption{Example of images of 20\lira\ banknotes }
\label{fig:test}
\end{figure}

The author of dataset already performed brightness adjustment, noise reduction and image flipping when necessary.\\
All images are in PNG format with a 1280 x 720 resolution.

\subsection{Preprocessing}
Taking into consideration what has already been said about the images, it is clear that there is no need to apply other forms of corrections. Therefore, the only steps necessary prior to the train phase are:
\begin{itemize}
	\item Image scaling and decoding
	\item Dataset loading and batch splitting
\end{itemize}

\subsubsection{Image Scaling}
All the images come in a 1280x720 resolution. Working with such high resolution it's not 
recommended when training a CNN as it would take a big tall on the training speed due to the increasing number of parameters and RAM usage. 
For this reason all the images are reduced by a scale factor of 5, adjusting their resolution to 140x256.\\
Every image is also decoded in a 3D tensor with 3 channels corresponding to its RGB values.

\subsubsection{Dataset loading and batch splitting}
For both the training and the validation datasets a list is created containing the path of their images. 
Every element in the lists is then mapped to an image-label. The lists are then used to create the actual dataset variables.\\
Each dataset is divided into batches. After some tweaking, a number of 32 elements per batch proved to be optimal for the considered application.\\
Each dataset is set to repeat, allowing for multiple epochs of training on the same batches. Moreover the training dataset is set to be prefetched: 
this allows the next batches to be loaded while the current one is being used, drastically reducing latency and improving throughput at the cost using additional memory.\\
Only the training dataset is shuffled as it is not really necessary with the validation dataset, since it is only used for evaluation.


\newpage
\section{Experiments and results}
Different models have been tested during the developing process; in this section some of those will be shown and the relative results will be discussed.
\subsection{Model summary}
For each tested model the following data will be reported:
\begin{itemize}
\item The NN architecture
\item Hyperparameters used
\item Data on accuracy for three repeated runs
\item Graph of one of the runs
\item Comments on the architecture and results
\end{itemize}
In the layer tables the input  layer will not be reported, as it always corresponds to resized image size (\texttt{144,256,3}).\\
Also note that some abbreviations are used in the Layer Config field in order to allow for the table to fit:
\begin{itemize}
\item \texttt{k} stands for \texttt{kernel size}
\item \texttt{s} stands for \texttt{strides}
\item \texttt{f} stands for \texttt{filters}
\item \texttt{p} stands for \texttt{pool size}
\item \texttt{r} stands for \texttt{rate}
\end{itemize}

%Commands needed for table
\newcommand{\conv}{Convolution(\texttt{Conv2d})}
\newcommand{\convP}[3]{\texttt{k=#1, s=#2, f=#3}}
\newcommand{\convKSF}[3]{\convP{#1}{#2}{#3}}

\newcommand{\flt}{Flatten(\texttt{Flatten})}

\newcommand{\dns}{Dense(\texttt{Dense})}
\newcommand{\dnsP}[1]{\texttt{u=#1}}

\newcommand{\pool}{MaxPooling(\texttt{MaxPooling2D})}
\newcommand{\poolN}{\texttt{p=2x2}}

\newcommand{\drop}{Dropout(\texttt{Dropout})}
\newcommand{\dropR}[1]{\texttt{r=#1}}

\newcommand{\bat}{Batch Norm.(\texttt{BatchN.})}

\newpage

\subsection{Models}

\subsubsection{Baseline Model}
\input{Models/baseline.tex}

\subsubsection{Convolution Model}
\input{Models/conv.tex}

\subsubsection{Convolution and Pooling Model}
\input{Models/conv_pool.tex}

\subsubsection{Convolution and Pooling Model with Dropout}
\input{Models/conv_pool_drop.tex}

\subsubsection{Batch Normalization Model}
\input{Models/bn.tex}

\subsection{Models comparison}
\input{Models/comparison.tex}






\newpage
\section{Conclusions}
As seen in the previous sections, after a few experiments, this project has been succesful in classifying the images of Turkish 
Lira banknotes with high accuracy and low data loss.
(altro?) aggiungere migliori risultati ottenuti - 




Esempio di citazione\cite{latexcompanion}

\newpage
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{9}
\bibitem{latexcompanion} 
Michel Goossens, Frank Mittelbach, and Alexander Samarin. 
\textit{The \LaTeX\ Companion}. 
Addison-Wesley, Reading, Massachusetts, 1993.

\bibitem{einstein} 
Albert Einstein. 
\textit{Zur Elektrodynamik bewegter K{\"o}rper}. (German) 
[\textit{On the electrodynamics of moving bodies}]. 
Annalen der Physik, 322(10):891â921, 1905.

\bibitem{knuthwebsite} 
Knuth: Computers and Typesetting,
\\\texttt{http://www-cs-faculty.stanford.edu/\~{}uno/abcde.html}
\end{thebibliography}


\end{document}
